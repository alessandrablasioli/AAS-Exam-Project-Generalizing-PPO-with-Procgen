{"episode_reward": 0.0, "episode_length": 76, "_timestamp": 1757074238.4836123, "_runtime": 6610.360294342041, "_step": 6293, "episode_reward_mean": 1.0, "episode_length_mean": 61.5, "episode_reward_max": 3.0, "episode_reward_min": 0.0, "num_episodes": 4, "policy_loss": -0.19123519957065582, "value_loss": 0.03587469831109047, "entropy": 2.6634674072265625, "update": 999, "eval_reward_mean": 1.3, "eval_reward_std": 2.0024984394500787, "_wandb": {"runtime": 6609}}