{"episode_reward": 0.0, "episode_length": 54, "_timestamp": 1757252193.259907, "_runtime": 21627.919137954712, "_step": 5384, "episode_reward_mean": 0.0, "episode_length_mean": 61.333333333333336, "episode_reward_max": 0.0, "episode_reward_min": 0.0, "num_episodes": 3, "policy_loss": 0.040927596390247345, "value_loss": 0.0009523005574010313, "entropy": 2.6445322036743164, "update": 999, "eval_reward_mean": 0.4, "eval_reward_std": 0.9165151389911681, "_wandb": {"runtime": 21627}}