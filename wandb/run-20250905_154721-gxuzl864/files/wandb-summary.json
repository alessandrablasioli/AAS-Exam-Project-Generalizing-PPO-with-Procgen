{"policy_loss": -0.29478728771209717, "value_loss": 0.3722709119319916, "entropy": 2.6755685806274414, "_timestamp": 1757089500.205471, "_runtime": 9458.529703140259, "_step": 2931, "update": 999, "eval_reward_mean": 0.0, "eval_reward_std": 0.0, "episode_reward": 10.0, "episode_length": 29, "episode_reward_mean": 10.0, "episode_length_mean": 84.66666666666667, "episode_reward_max": 10.0, "episode_reward_min": 10.0, "num_episodes": 3, "_wandb": {"runtime": 9458}}