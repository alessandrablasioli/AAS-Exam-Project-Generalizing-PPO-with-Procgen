{"episode_reward": 0.0, "episode_length": 94, "_timestamp": 1757135425.751339, "_runtime": 22586.93504190445, "_step": 5135, "episode_reward_mean": 0.3333333333333333, "episode_length_mean": 80.0, "episode_reward_max": 1.0, "episode_reward_min": 0.0, "num_episodes": 3, "policy_loss": -0.14522621035575867, "value_loss": 0.0017870445735752583, "entropy": 2.6710729598999023, "update": 999, "eval_reward_mean": 0.7, "eval_reward_std": 0.6403124237432849, "_wandb": {"runtime": 22586}}