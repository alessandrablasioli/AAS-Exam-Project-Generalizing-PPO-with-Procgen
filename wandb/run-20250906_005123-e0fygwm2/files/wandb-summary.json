{"episode_reward": 1.0, "episode_length": 60, "_timestamp": 1757112775.1787114, "_runtime": 91.41152429580688, "_step": 22, "episode_reward_mean": 0.0, "episode_length_mean": 66.0, "episode_reward_max": 0.0, "episode_reward_min": 0.0, "num_episodes": 1, "policy_loss": -0.1991003453731537, "value_loss": 0.00027681217761710286, "entropy": 2.6967239379882812, "update": 3, "eval_reward_mean": 1.2, "eval_reward_std": 1.16619037896906, "_wandb": {"runtime": 92}}