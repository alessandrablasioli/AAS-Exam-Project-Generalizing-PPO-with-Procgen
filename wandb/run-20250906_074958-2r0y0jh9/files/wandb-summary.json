{"episode_reward": 1.0, "episode_length": 43, "_timestamp": 1757169736.458806, "_runtime": 31937.72530913353, "_step": 6223, "episode_reward_mean": 0.6666666666666666, "episode_length_mean": 80.33333333333333, "episode_reward_max": 1.0, "episode_reward_min": 0.0, "num_episodes": 3, "policy_loss": -0.17576885223388672, "value_loss": 0.009431261569261551, "entropy": 2.6617722511291504, "update": 999, "eval_reward_mean": 0.9, "eval_reward_std": 1.3, "_wandb": {"runtime": 31936}}